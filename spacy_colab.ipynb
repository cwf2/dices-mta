{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/cwf2/dices-mta/blob/main/spacy_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "49cmysINN2WW"
   },
   "source": [
    "## Install packages\n",
    "\n",
    "This cell is necessary for Google Colab. It installs language models, local copies of the texts, and the DICES client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qo-_bFXQ18qw"
   },
   "outputs": [],
   "source": [
    "# install the language models\n",
    "!pip install https://huggingface.co/latincy/la_core_web_lg/resolve/main/la_core_web_lg-any-py3-none-any.whl\n",
    "!pip install https://huggingface.co/chcaa/grc_odycy_joint_trf/resolve/main/grc_odycy_joint_trf-any-py3-none-any.whl\n",
    "\n",
    "# install Capitains/Nautilus\n",
    "!pip install git+https://github.com/Capitains/Nautilus.git\n",
    "\n",
    "# install local text repositories\n",
    "!git clone https://github.com/cwf2/canonical-latinLit.git\n",
    "!git clone https://github.com/cwf2/canonical-greekLit.git\n",
    "\n",
    "# install DICES client\n",
    "!pip install git+https://github.com/cwf2/dices-client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DfzK_3ryOMrn"
   },
   "source": [
    "## Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aHiBxzopIliD"
   },
   "outputs": [],
   "source": [
    "# DICES client\n",
    "from dicesapi import DicesAPI\n",
    "from dicesapi.text import CtsAPI, spacy_load\n",
    "\n",
    "# necessary for retrieving text from local repositories\n",
    "from MyCapytain.resolvers.cts.local import CtsCapitainsLocalResolver\n",
    "from MyCapytain.resources.prototypes.metadata import UnknownCollection\n",
    "\n",
    "# Pandas for tabular data\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4BZxaHItOm-0"
   },
   "source": [
    "## Initialize DICES connection\n",
    "\n",
    "This is the DICES API, allowing us to search for speeches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IvITLFnSIy6O"
   },
   "outputs": [],
   "source": [
    "# create connection to DICES\n",
    "api = DicesAPI(logdetail=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ixWbp2gmO56w"
   },
   "source": [
    "## Initialize CTS connection\n",
    "\n",
    "This is the CTS API, allowing us to retrieve texts by URN. In this example, we not only instantiate a default CTS API, but we also create a *local resolver* that can serve texts from the local repositories we downloaded in the first cell.\n",
    "\n",
    "We have to do a little surgery to overwrite the default CTS API object's resolver with the local one.\n",
    "\n",
    "- Note: The resolver will generate a lot of errors; these can be ignored unless they pertain to a text you want to retrieve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PCGWPZiGLpC3"
   },
   "outputs": [],
   "source": [
    "# create a local resolver\n",
    "local_resolver = CtsCapitainsLocalResolver(['canonical-greekLit', 'canonical-latinLit'])\n",
    "\n",
    "# initialize the CTS API\n",
    "cts = CtsAPI(dices_api=api)\n",
    "\n",
    "# overwrite the default resolver\n",
    "cts._resolvers = {None: local_resolver}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iuX1P5RgQD3f"
   },
   "source": [
    "# Retrieve some speeches\n",
    "\n",
    "## First, get the speech metadata from DICES\n",
    "\n",
    "Using the API, we can search speeches using a set of key-value pairs. For now, JSON results from the API are paged, so if your search has a lot of results, you may have to wait for several pages to download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gHR6a81CMDO6"
   },
   "outputs": [],
   "source": [
    "# search for speeches by Achilles\n",
    "speeches = api.getSpeeches(spkr_name='Achilles')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QAV1l77FRA1m"
   },
   "source": [
    "## Retrieve the text of the speeches\n",
    "\n",
    "- When using a local resolver we have to explicitly trap errors resulting from missing texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tjIFdTzaMQHm"
   },
   "outputs": [],
   "source": [
    "# iterate over all the speeches\n",
    "#  - retrieve the text with CTS\n",
    "for s in speeches:\n",
    "    try:\n",
    "        s.passage = cts.getPassage(s)\n",
    "    except UnknownCollection:\n",
    "        s.passage = None\n",
    "        print(f'failed: {s}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7sNl_ZeJSWEq"
   },
   "source": [
    "## Natural language processing with SpaCy\n",
    "\n",
    "### Set the SpaCy language models\n",
    "\n",
    "Here, we're using different language models than the defaults. We downloaded these in the first cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W17DNln0S7Kc"
   },
   "outputs": [],
   "source": [
    "# initialize spacy models\n",
    "spacy_load(\n",
    "    latin_model = 'la_core_web_lg',\n",
    "    greek_model = 'grc_odycy_joint_trf',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O7TRGB2FTZCX"
   },
   "source": [
    "### Run the SpaCy pipeline to parse the text of each passage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jcu96kEMSYql"
   },
   "outputs": [],
   "source": [
    "for i, s in enumerate(speeches):\n",
    "    print(f'[{i+1}/{len(speeches)}] {s.author.name} {s.work.title} {s.l_range}', end=' ... ')\n",
    "    if s.passage is not None:\n",
    "        s.passage.runSpacyPipeline()\n",
    "        if s.passage.spacy_doc is not None:\n",
    "            print(f'{len(s.passage.spacy_doc)} tokens')\n",
    "        else:\n",
    "            print('failed')\n",
    "    else:\n",
    "        print('no text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ShZJa-iGgTjS"
   },
   "source": [
    "### Extract the token features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dM3bRaJIge4P"
   },
   "outputs": [],
   "source": [
    "token_table = pd.DataFrame(dict(\n",
    "    speech = s.id,\n",
    "    urn = s.work.urn,\n",
    "    author = s.author.name,\n",
    "    work = s.work.title,\n",
    "    l_fi = s.l_fi,\n",
    "    l_la = s.l_la,\n",
    "    spkr = [inst.name for inst in s.spkr],\n",
    "    addr = [inst.name for inst in s.addr],\n",
    "    line = s.passage.line_array[s.passage.getLineIndex(tok)]['n'],\n",
    "    lpos = s.passage.getLinePos(tok),\n",
    "    token = tok.text,\n",
    "    lemma = tok.lemma_,\n",
    "    pos = tok.pos_,\n",
    "    mood = tok.morph.get('Mood'),\n",
    "    tense = tok.morph.get('Tense'),\n",
    "    voice = tok.morph.get('Voice'),\n",
    "    person = tok.morph.get('Person'),\n",
    "    number = tok.morph.get('Number'),\n",
    "    case = tok.morph.get('Case'),\n",
    "    gender = tok.morph.get('Gender'),\n",
    "\n",
    ") for s in speeches if s.passage is not None for tok in s.passage.spacy_doc)\n",
    "\n",
    "display(token_table)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNLCrlZi/0B0sz28N7Sm82y",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
