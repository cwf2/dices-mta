{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNLCrlZi/0B0sz28N7Sm82y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cwf2/dices-mta/blob/main/spacy_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install packages\n",
        "\n",
        "This cell is necessary for Google Colab. It installs language models, local copies of the texts, and the DICES client."
      ],
      "metadata": {
        "id": "49cmysINN2WW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qo-_bFXQ18qw"
      },
      "outputs": [],
      "source": [
        "# install the language models\n",
        "!pip install https://huggingface.co/latincy/la_core_web_lg/resolve/main/la_core_web_lg-any-py3-none-any.whl\n",
        "!pip install https://huggingface.co/chcaa/grc_odycy_joint_trf/resolve/main/grc_odycy_joint_trf-any-py3-none-any.whl\n",
        "\n",
        "# install Capitains/Nautilus\n",
        "!pip install git+https://github.com/Capitains/Nautilus.git\n",
        "\n",
        "# install local text repositories\n",
        "!git clone https://github.com/cwf2/canonical-latinLit.git\n",
        "!git clone https://github.com/cwf2/canonical-greekLit.git\n",
        "\n",
        "# install DICES client\n",
        "!pip install git+https://github.com/cwf2/dices-client"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import statements"
      ],
      "metadata": {
        "id": "DfzK_3ryOMrn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DICES client\n",
        "from dicesapi import DicesAPI\n",
        "from dicesapi.text import CtsAPI, spacy_load\n",
        "\n",
        "# necessary for retrieving text from local repositories\n",
        "from MyCapytain.resolvers.cts.local import CtsCapitainsLocalResolver\n",
        "from MyCapytain.resources.prototypes.metadata import UnknownCollection\n",
        "\n",
        "# Pandas for tabular data\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "aHiBxzopIliD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize DICES connection\n",
        "\n",
        "This is the DICES API, allowing us to search for speeches."
      ],
      "metadata": {
        "id": "4BZxaHItOm-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create connection to DICES\n",
        "api = DicesAPI(logdetail=0)"
      ],
      "metadata": {
        "id": "IvITLFnSIy6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize CTS connection\n",
        "\n",
        "This is the CTS API, allowing us to retrieve texts by URN. In this example, we not only instantiate a default CTS API, but we also create a *local resolver* that can serve texts from the local repositories we downloaded in the first cell.\n",
        "\n",
        "We have to do a little surgery to overwrite the default CTS API object's resolver with the local one.\n",
        "\n",
        "- Note: The resolver will generate a lot of errors; these can be ignored unless they pertain to a text you want to retrieve."
      ],
      "metadata": {
        "id": "ixWbp2gmO56w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a local resolver\n",
        "local_resolver = CtsCapitainsLocalResolver(['canonical-greekLit', 'canonical-latinLit'])\n",
        "\n",
        "# initialize the CTS API\n",
        "cts = CtsAPI(dices_api=api)\n",
        "\n",
        "# overwrite the default resolver\n",
        "cts._resolvers = {None: local_resolver}"
      ],
      "metadata": {
        "id": "PCGWPZiGLpC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retrieve some speeches\n",
        "\n",
        "## First, get the speech metadata from DICES\n",
        "\n",
        "Using the API, we can search speeches using a set of key-value pairs. For now, JSON results from the API are paged, so if your search has a lot of results, you may have to wait for several pages to download."
      ],
      "metadata": {
        "id": "iuX1P5RgQD3f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# search for speeches by Achilles\n",
        "speeches = api.getSpeeches(spkr_name='Achilles')"
      ],
      "metadata": {
        "id": "gHR6a81CMDO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Retrieve the text of the speeches\n",
        "\n",
        "- When using a local resolver we have to explicitly trap errors resulting from missing texts."
      ],
      "metadata": {
        "id": "QAV1l77FRA1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# iterate over all the speeches\n",
        "#  - retrieve the text with CTS\n",
        "for s in speeches:\n",
        "    try:\n",
        "        s.passage = cts.getPassage(s)\n",
        "    except UnknownCollection:\n",
        "        s.passage = None\n",
        "        print(f'failed: {s}')"
      ],
      "metadata": {
        "id": "tjIFdTzaMQHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Natural language processing with SpaCy\n",
        "\n",
        "### Set the SpaCy language models\n",
        "\n",
        "Here, we're using different language models than the defaults. We downloaded these in the first cell."
      ],
      "metadata": {
        "id": "7sNl_ZeJSWEq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize spacy models\n",
        "spacy_load(\n",
        "    latin_model = 'la_core_web_lg',\n",
        "    greek_model = 'grc_odycy_joint_trf',\n",
        ")"
      ],
      "metadata": {
        "id": "W17DNln0S7Kc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run the SpaCy pipeline to parse the text of each passage"
      ],
      "metadata": {
        "id": "O7TRGB2FTZCX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, s in enumerate(speeches):\n",
        "    print(f'[{i+1}/{len(speeches)}] {s.author.name} {s.work.title} {s.l_range}', end=' ... ')\n",
        "    if s.passage is not None:\n",
        "        s.passage.runSpacyPipeline()\n",
        "        if s.passage.spacy_doc is not None:\n",
        "            print(f'{len(s.passage.spacy_doc)} tokens')\n",
        "        else:\n",
        "            print('failed')\n",
        "    else:\n",
        "        print('no text')"
      ],
      "metadata": {
        "id": "Jcu96kEMSYql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extract the token features"
      ],
      "metadata": {
        "id": "ShZJa-iGgTjS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "token_table = pd.DataFrame(dict(\n",
        "    speech = s.id,\n",
        "    urn = s.work.urn,\n",
        "    author = s.author.name,\n",
        "    work = s.work.title,\n",
        "    l_fi = s.l_fi,\n",
        "    l_la = s.l_la,\n",
        "    spkr = [inst.name for inst in s.spkr],\n",
        "    addr = [inst.name for inst in s.addr],\n",
        "    line = s.passage.line_array[s.passage.getLineIndex(tok)]['n'],\n",
        "    lpos = s.passage.getLinePos(tok),\n",
        "    token = tok.text,\n",
        "    lemma = tok.lemma_,\n",
        "    pos = tok.pos_,\n",
        "    mood = tok.morph.get('Mood'),\n",
        "    tense = tok.morph.get('Tense'),\n",
        "    voice = tok.morph.get('Voice'),\n",
        "    person = tok.morph.get('Person'),\n",
        "    number = tok.morph.get('Number'),\n",
        "    case = tok.morph.get('Case'),\n",
        "    gender = tok.morph.get('Gender'),\n",
        "\n",
        ") for s in speeches if s.passage is not None for tok in s.passage.spacy_doc)\n",
        "\n",
        "display(token_table)"
      ],
      "metadata": {
        "id": "dM3bRaJIge4P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}